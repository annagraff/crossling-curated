}
# Calculates the taxonomic diversity index
#
# The index calculation is per group (usually the top-level clade, i.e. family), with the parameter
# `group_indices` mapping groups to leaf taxa. This parameter can also be used to limit
# the calculation to certain groups only (we use it to speed up updates)
calculate_taxonomic_diversity <- function(taxonomy, group_indices) {
# no groups, nothing to compute
if (length(group_indices) == 0L) return(vctrs::vec_init(double(), nrow(taxonomy)))
# replace each node by how often it occurs in the sample
# these counts form the basis for the diversity measure (we prioritize retaining data from smaller branches)
#
# uneven taxonomies are equalized by counting NA nodes in the flat taxonomy as unique
counts <- calculate_counts(taxonomy[unlist(group_indices), , drop = FALSE])
# balance the taxonomic structure by only considering the unique levels
prods <- rowapply(counts, function(x) prod(unique(x)), .ptype = double())
# the taxonomic weights for each taxon are reciprocal geometric means of the (balanced) node level counts
# note: fractional exponent effectively pads each product to the full taxonomic depth
weights <- 1/(prods^(1/ncol(taxonomy)))
# scatter the weights back into the correct rows using group indices
weights <- vctrs::vec_assign(vctrs::vec_init(double(), nrow(taxonomy)), unlist(group_indices), weights)
# normalize the weights within individual groups
for (group in group_indices) weights[group] <- weights[group]/sum(weights[group])
weights
}
# Row-wise score using arithmetic mean
row_scores_arithmetic <- function(matrix) {
rowMeans(matrix)
}
# Row-wise score using geometric mean
row_scores_geometric <- function(matrix) {
ncol(matrix) > 1L || return(matrix)
# there is no rowProds
prod <- matrix[, 1L, drop = TRUE]
for(i in seq_len(ncol(matrix) - 1L)) {
prod <- prod*matrix[, i+1, drop = TRUE]
}
# geometric mean
prod^(1/ncol(matrix))
}
# Row-wise score using log odds
row_scores_log_odds <- function(matrix) {
ncol(matrix) > 1L || return(matrix)
# logistic transformation
# note: clamp the logit value to [-10, +10]
x <- pmax(pmin(as.vector(matrix), 0.9999546), 1 - 0.9999546)
x <- log(x/(1-x))
# average and transform back
matrix <- matrix(x, ncol = ncol(matrix), nrow = nrow(matrix))
means <- rowMeans(matrix)
scores <- exp(means)/(1+exp(means))
scores
}
# calculate initial importance weights
state$weights <- update_importance_weights_for_pruning_state(NULL, state)
View(state)
state$weights
# factory for pruned data promise creation
pruned_data_factory <- make_pruned_data_factory(data)
# pruning steps will be recorded here
densify_log <- make_log_entry_for_pruning_state(state, pruned_data_factory)
# utility that displays current coding density of the pruning process
current_coding_density <- function() {
if ((n <- nrow(densify_log)) == 0 || !is.finite(densify_log$coding_density[[n]])) return("")
sprintf("| current coding density %s%%", round(densify_log$coding_density[[n]], 2)*100)
}
# initial pruning of uninformative taxa
state <- prune_non_informative_data(state, min_variability = min_variability, .changes = function(changes) {
densify_log <<- vec_rbind(densify_log, make_log_entry_for_pruning_state(state, pruned_data_factory, changes))
})
View(state)
logical_log <-
densify(data = logical_for_pruning,
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean_weights = list(coding = 0.999, taxonomy = 1))
logical_log <-
densify(data = logical_for_pruning,
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean_weights = list(coding = 0.999, taxonomy = 0.9))
set.seed(1111)
logical_log <-
densify(data = logical_for_pruning,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean = density_mean,
min_variability = min_variability,
density_mean_weights = list(coding = 0.999, taxonomy = 1))
dr_arith_taxtrue <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "arithmetic",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 1))
logical_log <-
densify(data = logical_for_pruning,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean = density_mean,
min_variability = min_variability,
density_mean_weights = list(coding = 0.999, taxonomy = 1))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#"
)
# arithmetic mean, including and excluding taxonomic diversity
set.seed(2023)
dr_arith_taxtrue <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "arithmetic",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 1))
dr_arith_taxfalse <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "arithmetic",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 0))
# geometric mean, including and excluding taxonomic diversity
dr_geom_taxtrue <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "geometric",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 1))
dr_geom_taxfalse <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "geometric",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 0))
# log_odds mean, including and excluding taxonomic diversity
# varying weights when taxonomic diversity included
dr_lom_taxtrue_11 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 1))
dr_lom_taxtrue_099099 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.99, taxonomy = 0.99))
dr_lom_taxtrue_095095 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.95, taxonomy = 0.95))
dr_lom_taxtrue_090090 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.90, taxonomy = 0.90))
dr_lom_taxtrue_050050 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.50, taxonomy = 0.50))
dr_lom_taxtrue_1095 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 0.95))
dr_lom_taxtrue_0951 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.95, taxonomy = 1))
dr_lom_taxtrue_1090 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 0.90))
dr_lom_taxtrue_0901 <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "log_odds",
min_variability = 3,
density_mean_weights = list(coding = 0.90, taxonomy = 1))
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#"
)
# load packages
library(densify)
library(tidyverse)
# exclude languages from WALS that are not attributable to any entry in the glottolog taxonomy
WALS <- WALS[which(WALS$Glottocode %in% glottolog_languoids$id), ]
# ensure all missing and non-applicable information is coded as NA
WALS[WALS==""] <- NA
WALS[WALS=="?"] <- NA
WALS[WALS=="NA"] <- NA
# this is the flat glottolog taxonomy generated within the densify function
# with the input glottolog_languoids
flat_taxonomy_matrix <- as_flat_taxonomy_matrix(glottolog_languoids)
set.seed(2023)
dr_arith_taxtrue <-
densify(data = WALS,
taxonomy = glottolog_languoids,
taxon_id = "Glottocode",
density_mean = "arithmetic",
min_variability = 3,
density_mean_weights = list(coding = 1, taxonomy = 1))
setwd("../../crossling-curated/data/GBInd")
#### This script densifies the GBInd logical and statistical datasets
rm(list=ls())
# load packages
library(densify)
library(tidyverse)
library(gmt)
library(ggplot2)
# read functions
source("../functions.R")
# read in logical GBInd data
logical <- read.csv("output/logicalGBI/logicalGBI.csv") %>% select(-X)
# read in statistical GBInd data
statistical <- read.csv("output/statisticalGBI/statisticalGBI.csv") %>% select(-X)
# generate taxonomy matrix
taxonomy_matrix <- as_flat_taxonomy_matrix(glottolog_languoids)
# for densification, ensure all blanks, ? and "NA" are coded as NA
logical_for_pruning <- na_convert(logical)
statistical_for_pruning <- na_convert(statistical)
# specify parameters for densification
min_variability <- 3 # each variable must have at least 3 languages in its second-largest state
density_mean <- "log_odds"
# comment on weights: GB is quite dense, and part of the "NA"s on the column/variable side in both curations is explicitly wanted
# densification should thus be biased towards the taxonomic diversity criterion, expressed in a higher weight
# run densify, set seed for reproducibility
set.seed(1111)
logical_log <-
densify(data = logical_for_pruning,
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean_weights = list(coding = 0.999, taxonomy = 1))
statistical_log <-
densify(data = statistical_for_pruning,
min_variability = min_variability,
scoring = scoring,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
scoring_weights = list(coding = 0.999, taxonomy = 1))
statistical_log <-
densify(data = statistical_for_pruning,
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
taxon_id = "glottocode",
density_mean_weights = list(coding = 0.999, taxonomy = 1))
# prune to optima
# we include minimum row coding density, since NAs on language end should largely be random
# we include taxonomic index since densification here explicitly seeks to increase taxonomic diversity
logical_pruned <- prune(logical_log,
scoring_function = n_data_points*coding_density*row_coding_density_min*taxonomic_index^3)
statistical_pruned <- prune(statistical_log,
scoring_function = n_data_points*coding_density*row_coding_density_min*taxonomic_index^3)
# retrieve corresponding data from input (to re-establish differences between ? and NA)
logical_pruned <- logical[which(logical$glottocode%in%logical_pruned$glottocode), which(names(logical)%in%names(logical_pruned))]
statistical_pruned <- statistical[which(statistical$glottocode%in%statistical_pruned$glottocode), which(names(statistical)%in%names(statistical_pruned))]
x <- read.csv("output/logicalGBI/logicalGBI_pruned.csv") %>% select(-X)
x == logical_pruned
expect_true(x == logical_pruned)
all(x == logical_pruned)
all(x == logical_pruned, na.omit = T)
na.omit(x == logical_pruned, na.omit = T)
expect_true(na.omit(x == logical_pruned, na.omit = T))
library(testthat)
expect_true(na.omit(x == logical_pruned, na.omit = T))
expect_true(all(na.omit(x == logical_pruned, na.omit = T)))
x <- read.csv("output/statisticalGBI/statisticalGBI_pruned.csv") %>% select(-X)
expect_true(all(na.omit(x == statistical_pruned, na.omit = T)))
setwd("../TypLinkInd/")
#### This script densifies the full TypLinkInd logical and statistical datasets, as well as their domain-wise subsets (morphosyntax, phonology, lexicon)
rm(list=ls())
# load packages
library(densify)
library(tidyverse)
library(gmt)
library(ggplot2)
# read functions
source("../functions.R")
# read in logical TLI data
logical <- read.csv("output/logicalTLI/full/logicalTLI_full.csv") %>% select(-X)
# read in statistical TLI data
statistical <- read.csv("output/statisticalTLI/full/statisticalTLI_full.csv") %>% select(-X)
# generate taxonomy matrix
taxonomy_matrix <- as_flat_taxonomy_matrix(glottolog_languoids)
# for densification, ensure all blanks, ? and "NA" are coded as NA
logical_for_pruning <- na_convert(logical)
statistical_for_pruning <- na_convert(statistical)
# group both logical and statistical data in 4 sets: (1) full (morphosyntax+phonology+lexicon), (2) morphosyntax only, (3) phonology only, (4) lexicon only
logical_parameters <- read.csv("output/logicalTLI/cldf/parameters.csv")
logical_full_for_pruning <- logical_for_pruning
logical_morphosyntax_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Morphosyntax")$short.name)],1,function(x)length(na.omit(x)))>0), c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Morphosyntax")$short.name))]
logical_phonology_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Phonology")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Phonology")$short.name))]
logical_lexicon_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Lexicon")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Lexicon")$short.name))]
statistical_parameters <- read.csv("output/statisticalTLI/cldf/parameters.csv")
statistical_full_for_pruning <- statistical_for_pruning
statistical_morphosyntax_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Morphosyntax")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Morphosyntax")$short.name))]
statistical_phonology_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Phonology")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Phonology")$short.name))]
statistical_lexicon_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Lexicon")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Lexicon")$short.name))]
# specify parameters for densification
min_variability <- 3 # each variable must have at least 3 languages in its second-largest state
scoring <- "log_odds"
density_mean <- "log_odds"
#### This script densifies the full TypLinkInd logical and statistical datasets, as well as their domain-wise subsets (morphosyntax, phonology, lexicon)
rm(list=ls())
# load packages
library(densify)
library(tidyverse)
library(gmt)
library(ggplot2)
# read functions
source("../functions.R")
# read in logical TLI data
logical <- read.csv("output/logicalTLI/full/logicalTLI_full.csv") %>% select(-X)
# read in statistical TLI data
statistical <- read.csv("output/statisticalTLI/full/statisticalTLI_full.csv") %>% select(-X)
# generate taxonomy matrix
taxonomy_matrix <- as_flat_taxonomy_matrix(glottolog_languoids)
# for densification, ensure all blanks, ? and "NA" are coded as NA
logical_for_pruning <- na_convert(logical)
statistical_for_pruning <- na_convert(statistical)
# group both logical and statistical data in 4 sets: (1) full (morphosyntax+phonology+lexicon), (2) morphosyntax only, (3) phonology only, (4) lexicon only
logical_parameters <- read.csv("output/logicalTLI/cldf/parameters.csv")
logical_full_for_pruning <- logical_for_pruning
logical_morphosyntax_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Morphosyntax")$short.name)],1,function(x)length(na.omit(x)))>0), c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Morphosyntax")$short.name))]
logical_phonology_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Phonology")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Phonology")$short.name))]
logical_lexicon_for_pruning <- logical_for_pruning[which(apply(logical_for_pruning[which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Lexicon")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(logical_for_pruning)%in%filter(logical_parameters,domain == "Lexicon")$short.name))]
statistical_parameters <- read.csv("output/statisticalTLI/cldf/parameters.csv")
statistical_full_for_pruning <- statistical_for_pruning
statistical_morphosyntax_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Morphosyntax")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Morphosyntax")$short.name))]
statistical_phonology_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Phonology")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Phonology")$short.name))]
statistical_lexicon_for_pruning <- statistical_for_pruning[which(apply(statistical_for_pruning[which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Lexicon")$short.name)],1,function(x)length(na.omit(x)))>0),c(1,which(names(statistical_for_pruning)%in%filter(statistical_parameters,domain == "Lexicon")$short.name))]
# specify parameters for densification
min_variability <- 3 # each variable must have at least 3 languages in its second-largest state
density_mean <- "log_odds"
##### densify full curation
# comment on weights: TLI is very sparse in terms of coding density and in terms of taxonomic diversity
# we do not specify that taxonomy should be more important in trimming and provide equal weights for densify()
# run matrix optimisation, set a seed for reproducibility
set.seed(1111)
logical_full_log <-
densify(data = logical_full_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
set.seed(1111)
statistical_full_log <-
densify(data = statistical_full_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
# identify optima
pruned_logical_full_large <- prune(logical_full_log,
scoring_function = n_data_points * coding_density * taxonomic_index)
pruned_logical_full_small <- prune(logical_full_log,
scoring_function = n_data_points^3 * coding_density^3 * row_coding_density_min * taxonomic_index)
pruned_statistical_full_large <- prune(statistical_full_log,
scoring_function = n_data_points * coding_density * taxonomic_index)
pruned_statistical_full_small <- prune(statistical_full_log,
scoring_function = n_data_points^3 * coding_density^3 * row_coding_density_min * taxonomic_index)
# retrieve corresponding data from input (to re-establish differences between ? and NA)
pruned_logical_full_large <- logical[which(logical$glottocode%in%pruned_logical_full_large$glottocode), which(names(logical)%in%names(pruned_logical_full_large))]
pruned_logical_full_small <- logical[which(logical$glottocode%in%pruned_logical_full_small$glottocode), which(names(logical)%in%names(pruned_logical_full_small))]
pruned_statistical_full_large <- statistical[which(statistical$glottocode%in%pruned_statistical_full_large$glottocode), which(names(statistical)%in%names(pruned_statistical_full_large))]
pruned_statistical_full_small <- statistical[which(statistical$glottocode%in%pruned_statistical_full_small$glottocode), which(names(statistical)%in%names(pruned_statistical_full_small))]
# save pruned matrices
write.csv(pruned_logical_full_large,"output/logicalTLI/full/logicalTLI_full_pruned_large.csv")
write.csv(pruned_logical_full_small,"output/logicalTLI/full/logicalTLI_full_pruned_small.csv")
write.csv(pruned_statistical_full_large,"output/statisticalTLI/full/statisticalTLI_full_pruned_large.csv")
write.csv(pruned_statistical_full_small,"output/statisticalTLI/full/statisticalTLI_full_pruned_small.csv")
##### densify morphosyntax curation
# comment on weights: TLI morphosyntax is very sparse in terms of coding density (much like the full dataset) and also uneven in terms of taxonomic diversity
# we do not specify that taxonomy should be more important in trimming and provide equal weights for densify()
# run matrix optimisation, set seed for reproducibility
set.seed(2222)
logical_morphosyntax_log <-
densify(data = logical_morphosyntax_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
set.seed(2222)
statistical_morphosyntax_log <-
densify(data = statistical_morphosyntax_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
# set scoring function for identifying optimal number of iterations
# we want to densify the matrix whilst maintaining taxonomic diversity and create two densifications, one being larger but sparser and one being smaller but denser
# --> n_data_points * coding_density * taxonomic_index
# --> n_data_points^3 * coding_density^3 * row_coding_density_min * taxonomic_index
# identify optima
pruned_logical_morphosyntax_large <- prune(logical_morphosyntax_log,
scoring_function = n_data_points * coding_density * taxonomic_index)
pruned_logical_morphosyntax_small <- prune(logical_morphosyntax_log,
scoring_function = n_data_points^3 * coding_density^3 * row_coding_density_min * taxonomic_index)
pruned_statistical_morphosyntax_large <- prune(statistical_morphosyntax_log,
scoring_function = n_data_points * coding_density * taxonomic_index)
pruned_statistical_morphosyntax_small <- prune(statistical_morphosyntax_log,
scoring_function = n_data_points^3 * coding_density^3 * row_coding_density_min * taxonomic_index)
# retrieve corresponding data from input (to re-establish differences between ? and NA)
pruned_logical_morphosyntax_large <- logical[which(logical$glottocode%in%pruned_logical_morphosyntax_large$glottocode), which(names(logical)%in%names(pruned_logical_morphosyntax_large))]
pruned_logical_morphosyntax_small <- logical[which(logical$glottocode%in%pruned_logical_morphosyntax_small$glottocode), which(names(logical)%in%names(pruned_logical_morphosyntax_small))]
pruned_statistical_morphosyntax_large <- statistical[which(statistical$glottocode%in%pruned_statistical_morphosyntax_large$glottocode), which(names(statistical)%in%names(pruned_statistical_morphosyntax_large))]
pruned_statistical_morphosyntax_small <- statistical[which(statistical$glottocode%in%pruned_statistical_morphosyntax_small$glottocode), which(names(statistical)%in%names(pruned_statistical_morphosyntax_small))]
# save pruned matrices
write.csv(pruned_logical_morphosyntax_large,"output/logicalTLI/morphosyntax/logicalTLI_morphosyntax_pruned_large.csv")
write.csv(pruned_logical_morphosyntax_small,"output/logicalTLI/morphosyntax/logicalTLI_morphosyntax_pruned_small.csv")
write.csv(pruned_statistical_morphosyntax_large,"output/statisticalTLI/morphosyntax/statisticalTLI_morphosyntax_pruned_large.csv")
write.csv(pruned_statistical_morphosyntax_small,"output/statisticalTLI/morphosyntax/statisticalTLI_morphosyntax_pruned_small.csv")
##### densify lexicon curation
# comment on weights: TLI lexicon is quite sparse in terms of coding density (a bit less than the datasets above) and also uneven in terms of taxonomic diversity (but less strongly so than the full dataset).
# There are not many variables (just 27 (logical) or 25 (statistical))
# we do not specify that taxonomy should be more important for trimming and provide equal weights for densify()
# run matrix optimisation, set seed for reproducibility
set.seed(3333)
logical_lexicon_log <-
densify(data = logical_lexicon_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
set.seed(3333)
statistical_lexicon_log <-
densify(data = statistical_lexicon_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.999, taxonomy = 0.999))
# set scoring function for identifying optimal number of iterations
# we want to densify the matrix whilst maintaining taxonomic diversity; not many badly coded languages
# --> n_data_points * coding_density * taxonomic_index
# prune matrices to optima
pruned_logical_lexicon <- prune(logical_lexicon_log, scoring_function = n_data_points * coding_density * taxonomic_index)
pruned_statistical_lexicon <- prune(statistical_lexicon_log, scoring_function = n_data_points * coding_density * taxonomic_index)
# retrieve corresponding data from input (to re-establish differences between ? and NA)
pruned_logical_lexicon <- logical[which(logical$glottocode%in%pruned_logical_lexicon$glottocode), which(names(logical)%in%names(pruned_logical_lexicon))]
pruned_statistical_lexicon <- statistical[which(statistical$glottocode%in%pruned_statistical_lexicon$glottocode), which(names(statistical)%in%names(pruned_statistical_lexicon))]
# save pruned matrices
write.csv(pruned_logical_lexicon,"output/logicalTLI/lexicon/logicalTLI_lexicon_pruned.csv")
write.csv(pruned_statistical_lexicon,"output/statisticalTLI/lexicon/statisticalTLI_lexicon_pruned.csv")
##### densify phonology curation
# comment on weights: TLI phonology is rather dense (not particularly sparse in terms of coding density), but rather uneven in terms of taxonomic diversity
# still, we do not specify that taxonomy should be more important for trimming and provide equal weights for densify()
# run matrix optimisation, set seed for reproducibility
set.seed(4444)
logical_phonology_log <-
densify(data = logical_phonology_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.99, taxonomy = 0.99))
set.seed(4444)
statistical_phonology_log <-
densify(data = statistical_phonology_for_pruning,
taxon_id = "glottocode",
min_variability = min_variability,
density_mean = density_mean,
taxonomy = glottolog_languoids,
density_mean_weights = list(coding = 0.99, taxonomy = 0.99))
# set scoring function for identifying optimal number of iterations
# we want to densify the matrix whilst maintaining taxonomic diversity; the focus should strongly lie on trimming away languages from well-represented families
# --> n_data_points * coding_density * row_coding_density_min * taxonomic_index
pruned_logical_phonology <- prune(logical_phonology_log, scoring_function = n_data_points * coding_density * row_coding_density_min * taxonomic_index)
pruned_statistical_phonology <- prune(statistical_phonology_log, scoring_function = n_data_points * coding_density * row_coding_density_min * taxonomic_index)
# retrieve corresponding data from input (to re-establish differences between ? and NA)
pruned_logical_phonology <- logical[which(logical$glottocode%in%pruned_logical_phonology$glottocode), which(names(logical)%in%names(pruned_logical_phonology))]
pruned_statistical_phonology <- statistical[which(statistical$glottocode%in%pruned_statistical_phonology$glottocode), which(names(statistical)%in%names(pruned_statistical_phonology))]
# save pruned matrices
write.csv(pruned_logical_phonology,"output/logicalTLI/phonology/logicalTLI_phonology_pruned.csv")
write.csv(pruned_statistical_phonology,"output/statisticalTLI/phonology/statisticalTLI_phonology_pruned.csv")
